{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ffff1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Haar Cascade face detector loaded\n",
      "\n",
      "============================================================\n",
      "PERSON DETECTION RESULTS\n",
      "============================================================\n",
      "✓ Total persons detected: 13\n",
      "\n",
      "Detailed information:\n",
      "  Person 1:\n",
      "    - Position: (82, 288)\n",
      "    - Size: 67x67 pixels\n",
      "    - Confidence: 0.90\n",
      "    - Center: (115, 321)\n",
      "  Person 2:\n",
      "    - Position: (88, 341)\n",
      "    - Size: 67x67 pixels\n",
      "    - Confidence: 0.90\n",
      "    - Center: (121, 374)\n",
      "  Person 3:\n",
      "    - Position: (206, 318)\n",
      "    - Size: 60x60 pixels\n",
      "    - Confidence: 0.90\n",
      "    - Center: (236, 348)\n",
      "  Person 4:\n",
      "    - Position: (269, 868)\n",
      "    - Size: 61x61 pixels\n",
      "    - Confidence: 0.90\n",
      "    - Center: (299, 898)\n",
      "  Person 5:\n",
      "    - Position: (362, 331)\n",
      "    - Size: 62x62 pixels\n",
      "    - Confidence: 0.90\n",
      "    - Center: (393, 362)\n",
      "  Person 6:\n",
      "    - Position: (412, 233)\n",
      "    - Size: 37x37 pixels\n",
      "    - Confidence: 0.90\n",
      "    - Center: (430, 251)\n",
      "  Person 7:\n",
      "    - Position: (532, 337)\n",
      "    - Size: 70x70 pixels\n",
      "    - Confidence: 0.90\n",
      "    - Center: (567, 372)\n",
      "  Person 8:\n",
      "    - Position: (661, 301)\n",
      "    - Size: 64x64 pixels\n",
      "    - Confidence: 0.90\n",
      "    - Center: (693, 333)\n",
      "  Person 9:\n",
      "    - Position: (679, 368)\n",
      "    - Size: 79x79 pixels\n",
      "    - Confidence: 0.90\n",
      "    - Center: (718, 407)\n",
      "  Person 10:\n",
      "    - Position: (791, 286)\n",
      "    - Size: 67x67 pixels\n",
      "    - Confidence: 0.90\n",
      "    - Center: (824, 319)\n",
      "  Person 11:\n",
      "    - Position: (805, 776)\n",
      "    - Size: 102x188 pixels\n",
      "    - Confidence: 0.50\n",
      "    - Center: (856, 870)\n",
      "  Person 12:\n",
      "    - Position: (900, 267)\n",
      "    - Size: 85x85 pixels\n",
      "    - Confidence: 0.90\n",
      "    - Center: (942, 309)\n",
      "  Person 13:\n",
      "    - Position: (1173, 425)\n",
      "    - Size: 34x34 pixels\n",
      "    - Confidence: 0.90\n",
      "    - Center: (1190, 442)\n",
      "\n",
      "✓ Result saved: test_image-6.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class PersonCounterDL:\n",
    "    \"\"\"\n",
    "    Counts people using OpenCV's deep learning face detector\n",
    "    (DNN module with ResNet-based model - much more robust than Haar Cascade)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize face and eye detectors using pre-trained Haar Cascades\n",
    "        \"\"\"\n",
    "        cascade_path = cv2.data.haarcascades\n",
    "        \n",
    "        self.face_cascade = cv2.CascadeClassifier(\n",
    "            os.path.join(cascade_path, 'haarcascade_frontalface_default.xml')\n",
    "        )\n",
    "        self.eye_cascade = cv2.CascadeClassifier(\n",
    "            os.path.join(cascade_path, 'haarcascade_eye.xml')\n",
    "        )\n",
    "        \n",
    "        if self.face_cascade.empty():\n",
    "            raise RuntimeError(\"Could not load Haar Cascade face detector\")\n",
    "        if self.eye_cascade.empty():\n",
    "            print(\"⚠ Warning: Eye cascade not available (non-critical)\")\n",
    "        \n",
    "        self.use_eye_detection = not self.eye_cascade.empty()\n",
    "        print(\"✓ Haar Cascade face detector loaded\")\n",
    "    \n",
    "\n",
    "    def _detect_faces_haar(self, image):\n",
    "        \"\"\"\n",
    "        Fallback: Haar Cascade detection with validation\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.equalizeHist(gray)\n",
    "        \n",
    "        faces = self.face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.05,\n",
    "            minNeighbors=3,\n",
    "            minSize=(20, 20),\n",
    "            maxSize=(300, 300)\n",
    "        )\n",
    "        \n",
    "        # Validate detections to reduce false positives\n",
    "        validated_faces = []\n",
    "        for (x, y, w, h) in faces:\n",
    "            if self._is_valid_face(image, gray, x, y, w, h):\n",
    "                validated_faces.append((x, y, w, h, 0.9))\n",
    "        \n",
    "        return validated_faces\n",
    "    \n",
    "    def _is_valid_face(self, image, gray, x, y, w, h):\n",
    "        \"\"\"\n",
    "        Validate if detection is likely a real face\n",
    "        Checks: aspect ratio, skin color, edges, and optional eye detection\n",
    "        \"\"\"\n",
    "        # 1. Check aspect ratio - face should be roughly square\n",
    "        aspect_ratio = float(w) / h if h > 0 else 0\n",
    "        if not (0.6 < aspect_ratio < 1.4):  # Face is roughly square\n",
    "            return False\n",
    "        \n",
    "        # 2. Check for skin tone in the region (most reliable)\n",
    "        roi_bgr = image[y:y+h, x:x+w]\n",
    "        roi_hsv = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Count pixels that look like skin (HSV range)\n",
    "        lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "        upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "        skin_mask1 = cv2.inRange(roi_hsv, lower_skin, upper_skin)\n",
    "        \n",
    "        lower_skin2 = np.array([170, 20, 70], dtype=np.uint8)\n",
    "        upper_skin2 = np.array([180, 255, 255], dtype=np.uint8)\n",
    "        skin_mask2 = cv2.inRange(roi_hsv, lower_skin2, upper_skin2)\n",
    "        \n",
    "        skin_mask = cv2.bitwise_or(skin_mask1, skin_mask2)\n",
    "        skin_percentage = np.count_nonzero(skin_mask) / (w * h)\n",
    "        \n",
    "        if skin_percentage < 0.15:  # Should have some skin color\n",
    "            return False\n",
    "        \n",
    "        # 3. Check for edges (faces have texture, not smooth surfaces)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        edges = cv2.Canny(roi_gray, 50, 150)\n",
    "        edge_percentage = np.count_nonzero(edges) / (w * h)\n",
    "        \n",
    "        if edge_percentage < 0.05:  # Should have some edges/texture\n",
    "            return False\n",
    "        \n",
    "        # 4. Check contrast - faces have good contrast\n",
    "        contrast = roi_gray.std()\n",
    "        if contrast < 15:  # Low contrast = likely not a real face\n",
    "            return False\n",
    "        \n",
    "        # 5. Optional: Eye detection as bonus check (not required)\n",
    "        # Eyes are helpful but not every face angle detects eyes well\n",
    "        if self.use_eye_detection:\n",
    "            eyes = self.eye_cascade.detectMultiScale(roi_gray)\n",
    "            # If we detect eyes, great! But don't fail if we don't\n",
    "            # (some angles/lighting won't detect eyes)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _detect_edge_based_people(self, image):\n",
    "        \"\"\"\n",
    "        Fallback: edge-based detection for full body shots\n",
    "        Useful when face not visible or too small\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Edge detection\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        \n",
    "        # Morphological operations\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 50))\n",
    "        morph = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        people = []\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            # Person-sized objects\n",
    "            if 2000 < area < (h * w * 0.4):\n",
    "                x, y, bw, bh = cv2.boundingRect(contour)\n",
    "                aspect = float(bw) / bh if bh > 0 else 0\n",
    "                \n",
    "                # Person-like aspect ratio (taller than wide)\n",
    "                if 0.2 < aspect < 0.8:\n",
    "                    people.append((x, y, bw, bh, 0.5))\n",
    "        \n",
    "        return people\n",
    "    \n",
    "    def _nms(self, boxes, overlap_thresh=0.3):\n",
    "        \"\"\"\n",
    "        Non-maximum suppression: merge overlapping boxes\n",
    "        \"\"\"\n",
    "        if not boxes:\n",
    "            return []\n",
    "        \n",
    "        boxes = sorted(boxes, key=lambda b: b[4], reverse=True)  # Sort by confidence\n",
    "        keep = []\n",
    "        \n",
    "        while boxes:\n",
    "            current = boxes.pop(0)\n",
    "            keep.append(current)\n",
    "            \n",
    "            remaining = []\n",
    "            for box in boxes:\n",
    "                x1, y1, w1, h1, conf1 = current\n",
    "                x2, y2, w2, h2, conf2 = box\n",
    "                \n",
    "                # Calculate IoU (Intersection over Union)\n",
    "                xi1, yi1 = max(x1, x2), max(y1, y2)\n",
    "                xi2, yi2 = min(x1 + w1, x2 + w2), min(y1 + h1, y2 + h2)\n",
    "                \n",
    "                if xi2 > xi1 and yi2 > yi1:\n",
    "                    inter = (xi2 - xi1) * (yi2 - yi1)\n",
    "                    union = w1 * h1 + w2 * h2 - inter\n",
    "                    iou = inter / union if union > 0 else 0\n",
    "                    \n",
    "                    if iou <= overlap_thresh:\n",
    "                        remaining.append(box)\n",
    "                else:\n",
    "                    remaining.append(box)\n",
    "            \n",
    "            boxes = remaining\n",
    "        \n",
    "        return keep\n",
    "    \n",
    "    def count_persons(self, image_path, visualize=True, confidence_thresh=0.5):\n",
    "        \"\"\"\n",
    "        Main function: detect and count people\n",
    "        Uses multiple detection methods for robustness\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to image\n",
    "            visualize: Return annotated image\n",
    "            confidence_thresh: Confidence threshold for deep learning detector\n",
    "        \n",
    "        Returns:\n",
    "            count: Number of detected people\n",
    "            annotated: Annotated image\n",
    "            detections: List of detection boxes\n",
    "        \"\"\"\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Cannot read image: {image_path}\")\n",
    "        \n",
    "        # Resize if too large\n",
    "        h, w = image.shape[:2]\n",
    "        if w > 1280:\n",
    "            scale = 1280 / w\n",
    "            image = cv2.resize(image, (int(w * scale), int(h * scale)))\n",
    "        \n",
    "        all_detections = []\n",
    "        detection_methods = []\n",
    "        \n",
    "        # Method 1: Haar Cascade with face validation\n",
    "        haar_faces = self._detect_faces_haar(image)\n",
    "        all_detections.extend(haar_faces)\n",
    "        detection_methods.append(f\"Haar+Validation: {len(haar_faces)}\")\n",
    "        \n",
    "        # Method 3: Edge-based detection (for full body)\n",
    "        edge_people = self._detect_edge_based_people(image)\n",
    "        all_detections.extend(edge_people)\n",
    "        detection_methods.append(f\"Edge: {len(edge_people)}\")\n",
    "        \n",
    "        # Apply NMS to remove duplicates\n",
    "        final_detections = self._nms(all_detections, overlap_thresh=0.3)\n",
    "        final_detections = sorted(final_detections, key=lambda x: x[0])  # Sort by x position\n",
    "        \n",
    "        count = len(final_detections)\n",
    "        \n",
    "        # Visualization\n",
    "        annotated = image.copy() if visualize else None\n",
    "        \n",
    "        if visualize:\n",
    "            for idx, (x, y, bw, bh, conf) in enumerate(final_detections, 1):\n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(annotated, (x, y), (x + bw, y + bh), (0, 255, 0), 2)\n",
    "                \n",
    "                # Draw centroid\n",
    "                cx, cy = x + bw // 2, y + bh // 2\n",
    "                cv2.circle(annotated, (cx, cy), 5, (0, 0, 255), -1)\n",
    "                \n",
    "                # Label with confidence\n",
    "                label = f\"Person {idx} ({conf:.2f})\"\n",
    "                cv2.putText(annotated, label, (x, y - 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "            \n",
    "            # Total count\n",
    "            cv2.putText(annotated, f\"Total: {count} person(s)\", (10, 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "            \n",
    "            # Detection methods used\n",
    "            y_offset = 70\n",
    "            for method in detection_methods:\n",
    "                cv2.putText(annotated, method, (10, y_offset),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 0), 1)\n",
    "                y_offset += 25\n",
    "        \n",
    "        return count, annotated, final_detections\n",
    "\n",
    "\n",
    "def main(image_path=\"test_image.jpg\", save_output=True, confidence=0.5):\n",
    "    \"\"\"\n",
    "    Main execution\n",
    "    \"\"\"\n",
    "    counter = PersonCounterDL()\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"❌ Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        count, annotated, detections = counter.count_persons(\n",
    "            image_path, visualize=True, confidence_thresh=confidence\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PERSON DETECTION RESULTS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"✓ Total persons detected: {count}\")\n",
    "        \n",
    "        if detections:\n",
    "            print(f\"\\nDetailed information:\")\n",
    "            for idx, (x, y, w, h, conf) in enumerate(detections, 1):\n",
    "                print(f\"  Person {idx}:\")\n",
    "                print(f\"    - Position: ({x}, {y})\")\n",
    "                print(f\"    - Size: {w}x{h} pixels\")\n",
    "                print(f\"    - Confidence: {conf:.2f}\")\n",
    "                print(f\"    - Center: ({x + w//2}, {y + h//2})\")\n",
    "        \n",
    "        # Save result\n",
    "        if save_output:\n",
    "            # Add -1 suffix instead of overwriting\n",
    "            base_name = image_path.rsplit('.', 1)[0]\n",
    "            ext = image_path.rsplit('.', 1)[1] if '.' in image_path else 'jpg'\n",
    "            output_path = f\"{base_name}-1.{ext}\"\n",
    "            \n",
    "            # Handle multiple saves (if -1 exists, try -2, -3, etc.)\n",
    "            counter_suffix = 1\n",
    "            while os.path.exists(output_path):\n",
    "                counter_suffix += 1\n",
    "                output_path = f\"{base_name}-{counter_suffix}.{ext}\"\n",
    "            \n",
    "            cv2.imwrite(output_path, annotated)\n",
    "            print(f\"\\n✓ Result saved: {output_path}\")\n",
    "        \n",
    "        return annotated, count, detections\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return None, 0, []\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Try with different confidence thresholds if needed\n",
    "    result_img, person_count, details = main(image_path=\"test_image.jpg\", confidence=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
